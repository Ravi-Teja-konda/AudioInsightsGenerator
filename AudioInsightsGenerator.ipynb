{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravi-Teja-konda/AudioInsightsGenerator/blob/main/AudioInsightsGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI-Powered Audio Summarizer, Content Explorer, Perspective Generator, and Storyteller\n",
        "\n",
        "Welcome to this interactive AI-powered tool that not only summarizes and explores audio content but also adds unique perspectives, generates insightful ideas, and transforms information into engaging stories. This tool, powered by OpenAI's language models, takes the processing of audio content to the next level, allowing you to unlock new avenues of understanding and engagement with your content.\n",
        "\n",
        "## Features\n",
        "\n",
        "1. **Audio Summarization**: Upload any audio file and our tool will transcribe it and generate a concise summary. You can choose the format of the summary - bullet points, short paragraphs, or even a single concise sentence.\n",
        "\n",
        "2. **Filtering Custom Content**: Filter out the noise and focus on what matters to you. Input a keyword or topic of interest, and the tool will sift through the transcript to extract and highlight sections relevant to your input.\n",
        "\n",
        "3. **Idea Generation and Perspective Building**: This tool helps you look at your content from different angles, generating new ideas and providing unique perspectives that you may have missed.\n",
        "\n",
        "4.  **Cross-Questioning the Data**: Interact with your content in a more engaging way. Ask follow-up questions related to the filtered content and get relevant answers based on the context of the extracted content.\n",
        "5. **Storytelling**: Turn dry facts and data into compelling narratives. This storytelling feature takes key points from your audio content and weaves them into engaging narratives, making learning and information retention an enjoyable experience.\n",
        "\n",
        "## Benefits\n",
        "\n",
        "**Efficiency**: Save time by extracting key information from lengthy podcasts, lectures, meetings, or any other audio content.\n",
        "\n",
        "**Personalization**: Engage with the audio content in a personalized and interactive way by filtering content and asking follow-up questions.\n",
        "\n",
        "**Innovation**: Stimulate your thinking by exploring new perspectives and ideas generated from your content.\n",
        "\n",
        "**Engagement**: Increase engagement and retention by transforming information into narratives.\n",
        "\n",
        "**Accessibility**: Make information in audio format more accessible, enabling you to review and engage with it at your own pace and style.\n",
        "\n",
        "In a nutshell, our AI-powered tool opens up a whole new way of engaging with audio content. It's perfect for students reviewing lecture recordings, professionals catching up on industry podcasts, or any curious individuals eager to extract, explore, and engage with information more efficiently and creatively.\n"
      ],
      "metadata": {
        "id": "ppZKaWbI88FR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOqqWLPMLS7H",
        "outputId": "2dd2b7c2-7988-44c9-cdfd-648119bd9a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai requests pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import datetime\n",
        "import requests\n",
        "from google.colab import files\n",
        "from requests.exceptions import RequestException\n",
        "\n",
        "# You need to set your OpenAI API key here\n",
        "OPENAI_API_KEY = 'YOUR KEY HERE'\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def download_mp3(url, file_path):\n",
        "    try:\n",
        "        # Send a HTTP request to the URL of the MP3 file\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "        # Open the file in write mode to download the MP3 file\n",
        "        with open(file_path, 'wb') as audio:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:  # filter out keep-alive new chunks\n",
        "                    audio.write(chunk)\n",
        "        print(f\"Downloaded successfully: {file_path}\")\n",
        "        return file_path\n",
        "    except RequestException as e:\n",
        "        print(f\"Error during the request of {url}: {str(e)}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during the download of {url}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Transcribe audio file using Whisper API\n",
        "def transcribe_audio_whisper_api(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as file:\n",
        "            transcription = openai.Audio.transcribe(\"whisper-1\", file)\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        print(f\"{datetime.datetime.now()} [ERROR]: Error in transcription: {e}\")\n",
        "        return None\n",
        "\n",
        "# Analyze emotion from text using OpenAI GPT model\n",
        "def analyze_emotion(text):\n",
        "    try:\n",
        "        content = f\"What emotion is the following text expressing?\\n{text}\"\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": content}]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            max_tokens=200\n",
        "        )\n",
        "        emotion = response['choices'][0]['message']['content']\n",
        "        return emotion.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"{datetime.datetime.now()} [ERROR]: Error in emotion analysis: {e}\")\n",
        "        return None\n",
        "\n",
        "# Summarize text using OpenAI Chat model\n",
        "def summarize_text(text, style):\n",
        "    try:\n",
        "        # Using the chat endpoint\n",
        "        if style == \"1\":\n",
        "            content = f\"Summarize the following text in bullet points, ordered by importance:\\n{text}\"\n",
        "        elif style == \"2\":\n",
        "            content = f\"Summarize the following text in a short paragraph of 4 to 5 lines:\\n{text}\"\n",
        "        else:\n",
        "            content = f\"Summarize the following text concisely:\\n{text}\"\n",
        "\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": content}]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        summary = response['choices'][0]['message']['content']\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        print(f\"{datetime.datetime.now()} [ERROR]: Error in summarization: {e}\")\n",
        "        return None\n",
        "\n",
        "# User input for source of MP3 file\n",
        "print(\"Select the source of MP3 file:\")\n",
        "print(\"1 - Upload File\")\n",
        "print(\"2 - Insert MP3 Link\")\n",
        "source = input(\"Enter 1 or 2: \")\n",
        "\n",
        "file_path = None\n",
        "if source == \"1\":\n",
        "    # Upload the MP3 file\n",
        "    uploaded = files.upload()\n",
        "    for mp3_filename in uploaded.keys():\n",
        "        print(f\"{datetime.datetime.now()} [INFO]: User uploaded file '{mp3_filename}'\")\n",
        "        file_path = mp3_filename\n",
        "elif source == \"2\":\n",
        "    # Download the MP3 file from the given link\n",
        "    url = input(\"Enter the MP3 link: \")\n",
        "    file_path = \"audio.mp3\"  # you can set to any path you want\n",
        "    file_path = download_mp3(url, file_path)\n",
        "else:\n",
        "    print(\"Invalid option selected. Please select either 1 or 2.\")\n",
        "\n",
        "if file_path:\n",
        "    # Transcribe the audio using Whisper API\n",
        "    print(f\"{datetime.datetime.now()} [INFO]: Transcribing audio...\")\n",
        "    transcription = transcribe_audio_whisper_api(file_path)\n",
        "\n",
        "    # User input for summarization style\n",
        "    print(\"Select summarization style:\")\n",
        "    print(\"1 - Bullet Points\")\n",
        "    print(\"2 - Short Paragraph\")\n",
        "    print(\"3 - Concise\")\n",
        "    style = input(\"Enter 1, 2, or 3: \")\n",
        "\n",
        "    # Analyze emotion from the transcription using OpenAI GPT model\n",
        "    if transcription:\n",
        "        print(f\"{datetime.datetime.now()} [INFO]: Analyzing emotion...\")\n",
        "        emotion = analyze_emotion(transcription)\n",
        "        print(f\"{datetime.datetime.now()} [INFO]: Emotion: {emotion}\")\n",
        "\n",
        "        # Summarize the transcription using OpenAI Chat model\n",
        "        print(f\"{datetime.datetime.now()} [INFO]: Summarizing text...\")\n",
        "        summary = summarize_text(transcription, style)\n",
        "        print(f\"{datetime.datetime.now()} [INFO]: Summary: {summary}\")\n",
        "\n",
        "        # Download the summary as a text file\n",
        "        with open('summary.txt', 'w') as f:\n",
        "            f.write(f\"Emotion: {emotion}\\n\\n\")\n",
        "            f.write(summary)\n",
        "        files.download('summary.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "6HmmcGmqNYVE",
        "outputId": "33375c41-ad41-4098-a4ca-a74622d1b997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select the source of MP3 file:\n",
            "1 - Upload File\n",
            "2 - Download Link\n",
            "Enter 1 or 2: 2\n",
            "Enter the MP3 download link: https://dcs.megaphone.fm/ADV8883406591.mp3?key=c4243626894dc56d739288d99305fc87&request_event_id=3ac03551-3a00-4928-ad7c-928000bfe493\n",
            "Downloaded successfully: audio.mp3\n",
            "2023-06-29 15:54:56.578581 [INFO]: Transcribing audio...\n",
            "Select summarization style:\n",
            "1 - Bullet Points\n",
            "2 - Short Paragraph\n",
            "3 - Concise\n",
            "Enter 1, 2, or 3: 1\n",
            "2023-06-29 15:55:51.916133 [INFO]: Analyzing emotion...\n",
            "2023-06-29 15:55:53.151458 [INFO]: Emotion: The emotion expressed in the text can be described as informative and engaging.\n",
            "2023-06-29 15:55:53.152520 [INFO]: Summarizing text...\n",
            "2023-06-29 15:56:00.677209 [INFO]: Summary: - Warren Buffett's investing strategy of investing in wonderful companies at a fair price is simple but not commonly followed\n",
            "- There are many get-rich-quick schemes on the internet, but most of them are scams\n",
            "- A man named Evaldas Rymouskis successfully scammed Facebook and Google out of millions by posing as Quanta Computer and sending fake invoices\n",
            "- Rymouskis and his team were able to trick the companies into sending the payments to their own bank accounts\n",
            "- Rymouskis used social engineering tactics to gather information and execute his scam\n",
            "- He also had a system in place to launder the stolen money and move it into different bank accounts around the world\n",
            "- Eventually, Rymouskis was arrested and sentenced to five years in prison, and Google and Facebook were able to recover some of their losses\n",
            "- Business Email Compromise (BEC) scams like Rymouskis' have caused over $10 billion in losses from 2013 to 2019\n",
            "- Companies should take protective measures and educate their employees to defend against BEC scams\n",
            "- This story highlights the importance of security being everyone's responsibility in a company\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bc1a29df-081a-4ac1-a659-7168e2866f7d\", \"summary.txt\", 1210)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering and Cross-Questioning Custom Content\n",
        "\n",
        "In this cell, we are implementing a feature that not only allows you to filter custom content from the transcript but also supports cross-questioning the data from the transcript. This can be particularly useful if you are interested in a specific topic or subject matter discussed in the audio file and want to explore it further by asking follow-up questions.\n",
        "\n",
        "The cell uses OpenAI's GPT model to extract and focus on content that is relevant to a user-specified topic or keyword and generate responses to user-posed questions related to this content.\n",
        "\n",
        "## How it Works:\n",
        "1.The user is prompted to input the topic or keyword for which they want to filter the content.\n",
        "\n",
        "2.The cell then sends a request to OpenAI's GPT model, asking it to extract content that is focused on the topic or keyword specified by the user.\n",
        "\n",
        "3.The extracted content is displayed, and the user is then able to input a follow-up question related to the extracted content.\n",
        "\n",
        "4.The cell sends this follow-up question to the GPT model, which generates a response based on the context provided by the extracted content.\n",
        "\n",
        "5.The user is given the option to download both the filtered content and the question-answer pairs as a text file.\n",
        "\n",
        "## Use Case:\n",
        "For instance, if you have a lengthy podcast transcript and you are only interested in the segments that discuss \"investment strategies,\" you can input \"investment strategies\" as the keyword. The cell will then extract and present the portions of the transcript that are relevant to investment strategies. You can then pose a question like \"What are the recommended investment strategies?\" and the model will generate a response based on the filtered content.\n",
        "\n",
        "This feature can save time and effort by helping you to quickly locate and focus on the information that is most relevant to your interests or needs, and deepen your understanding by enabling you to ask follow-up questions.\n"
      ],
      "metadata": {
        "id": "LRZyjqZW0v85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter custom content from text using OpenAI GPT model\n",
        "def filter_custom_content(text, user_input):\n",
        "    try:\n",
        "        content = f\"Extract content from the following text that is focused on {user_input}, and ensure the content in bullet points:\\n{text}\"\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": content}]\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        filtered_content = response['choices'][0]['message']['content']\n",
        "        return filtered_content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"{datetime.datetime.now()} [ERROR]: Error in filtering custom content: {e}\")\n",
        "        return None\n",
        "\n",
        "# User input for content filtering\n",
        "user_input = input(\"Enter the topic you want to filter the content for (e.g. investment strategies): \")\n",
        "\n",
        "# Filter custom content from the transcript using OpenAI GPT model\n",
        "if transcription:\n",
        "    print(f\"{datetime.datetime.now()} [INFO]: Filtering custom content...\")\n",
        "    filtered_content = filter_custom_content(transcription, user_input)\n",
        "    print(f\"{datetime.datetime.now()} [INFO]: Filtered Content: {filtered_content}\")\n",
        "\n",
        "    # Download the filtered content as a text file\n",
        "    with open('filtered_content.txt', 'w') as f:\n",
        "        f.write(filtered_content)\n",
        "    files.download('filtered_content.txt')"
      ],
      "metadata": {
        "id": "_ruTOJ5FNcLy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "e8a68c73-fe46-4582-bc26-dea605fc6add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic you want to filter the content for (e.g. investment strategies): what is the hacking method used \n",
            "2023-06-29 15:56:34.044064 [INFO]: Filtering custom content...\n",
            "2023-06-29 15:56:38.505056 [INFO]: Filtered Content: - The hacker used a method known as Business Email Compromise (BEC) scam\n",
            "- The hacker posed as a company called Quanta Computer and issued a fake invoice to Facebook\n",
            "- The hacker altered the invoice to change the payment location to their own bank account\n",
            "- The hacker also conducted a BEC scam against Google using similar techniques\n",
            "- The hacker set up bank accounts in different countries to launder the stolen money\n",
            "- The scheme allowed the hacker to extract $23 million from Google and $98 million from Facebook\n",
            "- The scam was eventually discovered, leading to the hacker's arrest and subsequent sentencing to five years in prison\n",
            "- BEC scams have resulted in over $10 billion in losses reported to the Internet Crime Complaint Center between 2013 and 2019.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c92f3ba1-776b-46ed-9db8-4c6102bc3d6d\", \"filtered_content.txt\", 762)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turning Transcripts into Stories with Real-World Examples\n",
        "\n",
        "In this cell, we are implementing a feature to turn transcripts into stories integrated with real-world examples. This can make the content more engaging and relatable, especially for educational purposes.\n",
        "\n",
        "## How it Works:\n",
        "1. Characters are introduced to represent key concepts from the transcript.\n",
        "2. A plot is developed aligning with the logical progression of the transcript.\n",
        "3. The user can choose a narrative style or use the default linear narrative.\n",
        "4. OpenAI's GPT model is used to create the story.\n",
        "\n",
        "This approach utilizes storytelling as an effective tool for learning and engagement.\n"
      ],
      "metadata": {
        "id": "MNkgliRN2I2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def turn_transcript_into_story(transcript, narrative_style='linear narrative'):\n",
        "    try:\n",
        "        # Prepare content for the chat model\n",
        "        content = f\"Turn the following transcript into an engaging story with real-world examples and ensure the content in bullet points.The narrative style should be a {narrative_style}:\\n{transcript}\"\n",
        "        # Creating messages to send to the model\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that can convert transcripts into engaging stories with characters and real-world examples.\"}, {\"role\": \"user\", \"content\": content}]\n",
        "        # Sending request to OpenAI API\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        # Extracting the story from the response\n",
        "        story = response['choices'][0]['message']['content']\n",
        "        return story.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"{datetime.datetime.now()} [ERROR]: Error in turning transcript into story: {e}\")\n",
        "        return None\n",
        "\n",
        "# User input for narrative style (optional)\n",
        "narrative_style_input = input(\"Enter the narrative style you want for the story (e.g. nonlinear, hero’s journey) or leave blank for default linear narrative: \")\n",
        "\n",
        "# Turn transcript into story using OpenAI GPT model\n",
        "if transcription:\n",
        "    print(f\"{datetime.datetime.now()} [INFO]: Turning transcript into a story...\")\n",
        "    story = turn_transcript_into_story(transcription, narrative_style=narrative_style_input or 'linear narrative')\n",
        "    print(f\"{datetime.datetime.now()} [INFO]: Story: {story}\")\n",
        "\n",
        "    # Download the story as a text file\n",
        "    with open('story.txt', 'w') as f:\n",
        "        f.write(story)\n",
        "    files.download('story.txt')"
      ],
      "metadata": {
        "id": "ARmR4Y2U2KwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Idea Generation and Perspective Building\n",
        "\n",
        "This cell offers a unique feature of generating ideas and building perspectives from the transcript content. Leveraging the power of OpenAI's GPT model, it extracts unique insights and new ideas, providing a fresh perspective on the discussed content.\n",
        "\n",
        "## How it Works:\n",
        "1. The user is asked to input a specific perspective they're interested in. This input is optional, and if left blank, general ideas will be generated.\n",
        "\n",
        "2. The transcript is then processed through OpenAI's GPT model, which is directed to generate ideas and unique insights from the content.\n",
        "\n",
        "3. The generated ideas and perspectives are displayed in a bullet-point format. Each unique idea or insight is displayed as a separate bullet point.\n",
        "\n",
        "4. The user is given the option to download the generated ideas and perspectives as a text file.\n",
        "\n",
        "## Use cases\n",
        "\n",
        "This feature can be particularly useful when dealing with informational content where you seek to derive unique insights or brainstorm new ideas. By inputting a specific perspective, you can focus the generated ideas around that theme, thereby gaining targeted insights.\n",
        "\n",
        "For instance, if you're listening to a business podcast and wish to generate ideas around \"innovative marketing strategies\", you can input this as your perspective, and the cell will generate ideas centered around this theme.\n",
        "\n",
        "By offering fresh perspectives and unique insights, this tool can assist in brainstorming sessions, content creation, research, and much more, thus acting as your AI-powered ideation partner"
      ],
      "metadata": {
        "id": "xlmUlwfXCX1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_perspectives(transcript, perspective=None):\n",
        "    try:\n",
        "        # Prepare content for the chat model\n",
        "        if perspective:\n",
        "            content = f\"Generate unique insights and new ideas from the following transcript with the perspective of {perspective}. Each idea should be a separate bullet point:\\n{transcript}\"\n",
        "        else:\n",
        "            content = f\"Generate unique insights and new ideas from the following transcript. Each idea should be a separate bullet point:\\n{transcript}\"\n",
        "        # Creating messages to send to the model\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that can generate ideas and build perspectives from a given transcript.\"}, {\"role\": \"user\", \"content\": content}]\n",
        "        # Sending request to OpenAI API\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=messages,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        # Extracting the ideas from the response\n",
        "        ideas = response['choices'][0]['message']['content']\n",
        "        return ideas.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"{datetime.datetime.now()} [ERROR]: Error in generating perspectives: {e}\")\n",
        "        return None\n",
        "\n",
        "# User input for perspective (optional)\n",
        "perspective_input = input(\"Enter a perspective you want for the ideas or leave blank for general ideas: \")\n",
        "\n",
        "# Generate ideas and perspectives using OpenAI GPT model\n",
        "if transcription:\n",
        "    print(f\"{datetime.datetime.now()} [INFO]: Generating perspectives from the transcript...\")\n",
        "    ideas = generate_perspectives(transcription, perspective=perspective_input)\n",
        "    print(f\"{datetime.datetime.now()} [INFO]: Generated Ideas and Perspectives: \\n{ideas}\")\n",
        "\n",
        "    # Download the ideas as a text file\n",
        "    with open('ideas.txt', 'w') as f:\n",
        "        f.write(ideas)\n",
        "    files.download('ideas.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "nBSHyqf7_dij",
        "outputId": "53eac1f6-8c73-439c-8d64-ac69f65c5f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a perspective you want for the ideas or leave blank for general ideas: BEC as a software\n",
            "2023-06-29 15:57:13.307844 [INFO]: Generating perspectives from the transcript...\n",
            "2023-06-29 15:57:19.728009 [INFO]: Generated Ideas and Perspectives: \n",
            "- BEC software can detect and prevent phishing attacks by analyzing email headers and domain reputations. \n",
            "- BEC software can provide advanced security measures to protect against social engineering attacks, especially in financial transactions.\n",
            "- BEC software can automate compliance processes for companies, reducing the time spent on manual evidence collection.\n",
            "- BEC software can integrate with banking systems to identify suspicious transactions and flag potential fraud attempts.\n",
            "- BEC software can provide training and education materials for employees to increase awareness and prevent falling victim to BEC scams.\n",
            "- BEC software can monitor and analyze financial activities within a company to detect unusual patterns or suspicious behavior.\n",
            "- BEC software can analyze email communications for signs of unauthorized access or malicious activity.\n",
            "- BEC software can implement multi-factor authentication and encryption measures to enhance the security of financial transactions.\n",
            "- BEC software can provide real-time alerts and notifications when suspicious activity is detected, allowing for immediate intervention.\n",
            "- BEC software can analyze and assess the legitimacy of invoices and payment requests to prevent unauthorized transactions.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b90708e0-e868-4a01-a1bb-8ea45afe9583\", \"ideas.txt\", 1247)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}